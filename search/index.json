[{"content":"Introduction\rA GitHub personal home page, officially called a profile, is a personal GitHub presentation master page written in Markdown. In this article, we\u0026rsquo;ll demonstrate how to add a funny snake animation to the GitHub profile page.\nThe Snake animation is actually a kind of “heat map”, each small grid corresponds to each day, the grid is gray by default, where the green grid means we submitted code on that day, the darker the color of the grid, the more times we committed code on that day.\nPre-Conditions\rGitHub Accounts Some GitHub commits Implementation Steps\rStep 1: Create the Repository\rCreate a new repository with the same name as your GitHub username and select Add a README file.\nFor example, I would create a serendipityerr repository. After filling in the repository name (same as your GitHub username), some information would pop up like:\n1 serendipityerr/serendipityerr is a ✨️special✨️ repository that you can use to add a README.md to your GitHub profile. Make sure it\u0026#39;s public and initialize it with a README to get started. Step 2: New Action and Workflow\rClick on Actions in the repository you just created to enter the website like https://github.com/serendipityerr/serendipityerr/actions.\nClick on New workflow in the left side and select Skip this and set up a workflow yourself .\nIn the main.yml, copy and paste the following codes:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 name: generate animation on: # run automatically every 24 hours schedule: - cron: \u0026#34;0 */24 * * *\u0026#34; # allows to manually run the job at any time workflow_dispatch: # run on every push on the master branch push: branches: - main jobs: generate: runs-on: ubuntu-latest timeout-minutes: 10 steps: # generates a snake game from a github user (\u0026lt;github_user_name\u0026gt;) contributions graph, output a svg animation at \u0026lt;svg_out_path\u0026gt; - name: generate github-contribution-grid-snake.svg uses: Platane/snk/svg-only@v3 with: github_user_name: ${{ github.repository_owner }} outputs: | dist/github-contribution-grid-snake.svg dist/github-contribution-grid-snake-dark.svg?palette=github-dark env: GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }} # push the content of \u0026lt;build_dir\u0026gt; to a branch # the content will be available at https://raw.githubusercontent.com/\u0026lt;github_user\u0026gt;/\u0026lt;repository\u0026gt;/\u0026lt;target_branch\u0026gt;/\u0026lt;file\u0026gt; , or as github page - name: push github-contribution-grid-snake.svg to the output branch uses: crazy-max/ghaction-github-pages@v3.1.0 with: target_branch: output build_dir: dist env: GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }} Click on Commit changes...\nClick on Run workflow\nCheck whether successfully pushed, if successful, turn on Step 3. If not successful, turn to Debug part.\nStep 3: Revise README.md to Demonstrate the Action\rAdd the following codes in the README.md and please DO NOT FORGET to change the serendipityerr to your GitHub username:\n1 2 3 4 5 \u0026lt;picture\u0026gt; \u0026lt;source media=\u0026#34;(prefers-color-scheme: dark)\u0026#34; srcset=\u0026#34;https://raw.githubusercontent.com/serendipityerr/serendipityerr/output/github-contribution-grid-snake-dark.svg\u0026#34;\u0026gt; \u0026lt;source media=\u0026#34;(prefers-color-scheme: light)\u0026#34; srcset=\u0026#34;https://raw.githubusercontent.com/serendipityerr/serendipityerr/output/github-contribution-grid-snake.svg\u0026#34;\u0026gt; \u0026lt;img alt=\u0026#34;github contribution grid snake animation\u0026#34; src=\u0026#34;https://raw.githubusercontent.com/serendipityerr/serendipityerr/output/github-contribution-grid-snake.svg\u0026#34;\u0026gt; \u0026lt;/picture\u0026gt; Preview the changes to check if successfully deployed and Click on Commit changes....\nDebugging for the Potential Problems\rFailed to commit the main.yml in the workflow.\rWhen I attempted to commit the main.yml in the workflow, I found error All checks have failed. 1 failing check. In detail:\n1 2 3 4 5 Pushing dist directory to output branch on serendipityerr/serendipityerr repo /usr/bin/git push --force ***github.com/serendipityerr/serendipityerr.git output remote: Permission to serendipityerr/serendipityerr.git denied to github-actions[bot]. fatal: unable to access \u0026#39;https://github.com/serendipityerr/serendipityerr.git/\u0026#39;: The requested URL returned error: 403 Error: The process \u0026#39;/usr/bin/git\u0026#39; failed with exit code 128 Solutions\nSetup GitHub personal access: Actions deployed require access to your repository.\nClick on your avatar in the upper right corner\n$\\rightarrow$ Settings\n$\\rightarrow$ Developer settings\n$\\rightarrow$ Personal access tokens\n$\\rightarrow$ Tokens (classic)\n$\\rightarrow$ New personal access token or Click on the existing token\n$\\rightarrow$ Select all the scopes and choose No expiration\n$\\rightarrow$ Remember the TOKEN (it can\u0026rsquo;t be viewed after the page is closed!!!!)\n$\\rightarrow$ Go back to the repository, click on Setting - Secrets - Actions - New repository secrets. Name is ACCESS_TOKEN and Value is the TOKEN you just got.\nRevise the main.yml and Add two lines of codes:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 name: generate animation permissions: contents: write on: # run automatically every 24 hours schedule: - cron: \u0026#34;0 */24 * * *\u0026#34; # allows to manually run the job at any time workflow_dispatch: # run on every push on the master branch push: branches: - main jobs: generate: runs-on: ubuntu-latest timeout-minutes: 10 steps: # generates a snake game from a github user (\u0026lt;github_user_name\u0026gt;) contributions graph, output a svg animation at \u0026lt;svg_out_path\u0026gt; - name: generate github-contribution-grid-snake.svg uses: Platane/snk/svg-only@v3 with: github_user_name: ${{ github.repository_owner }} outputs: | dist/github-contribution-grid-snake.svg dist/github-contribution-grid-snake-dark.svg?palette=github-dark env: GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }} # push the content of \u0026lt;build_dir\u0026gt; to a branch # the content will be available at https://raw.githubusercontent.com/\u0026lt;github_user\u0026gt;/\u0026lt;repository\u0026gt;/\u0026lt;target_branch\u0026gt;/\u0026lt;file\u0026gt; , or as github page - name: push github-contribution-grid-snake.svg to the output branch uses: crazy-max/ghaction-github-pages@v3.1.0 with: target_branch: output build_dir: dist env: GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }} Turn on Step 2 and the problem is solved.\nFinal Animated Demo\rThe final results of my GitHub profile page can be found here: https://github.com/serendipityerr. ","date":"2025-02-20T11:14:33+08:00","image":"https://raw.githubusercontent.com/serendipityerr/serendipityerr/output/github-contribution-grid-snake.svg","permalink":"https://example.com/p/add-a-funny-snake-animation-to-your-github-profile-page/","title":"Add a Funny Snake Animation to Your GitHub Profile Page"},{"content":"HTML入门\rHTML(Hyper Text Markup Language)：超文本标记语言，用来描述网页的语言。\nHTML不是编程语言，是标记语言。\n所谓超文本，有2层含义：\n可以加入图片、声音动画、多媒体等内容(超越了文本限制)。 还可以从一个文件跳转到另一个文件，与世界各地主机的文件连接(超级链接文本)。 浏览器内核（渲染引擎）：负责读取网页内容，整理讯息，计算网页的显示方式并显示页面。\nWeb标准的构成\r主要包括结构(Structure)、表现(Presentation)和行为(Behavior)三个方面。\n结构：结构用于对网页元素进行整理和分类，现阶段主要学的是HTML。 表现：表现用于设置网页元素的版式、颜色、大小等外观样式，主要指的是css。 行为：行为是指网页模型的定义及交互的编写，现阶段主要学的是Javascript Web标准提出的最佳体验方案：结构、样式、行为相分离。 结构写到HTML文件中，表现写到css文件中，行为写到JavaScript文件中。 语法\r标签关系\r并列：\n1 2 3 4 \u0026lt;head\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;/body\u0026gt; 包含：\n1 2 3 \u0026lt;head\u0026gt; \u0026lt;title\u0026gt; \u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; 基本结构\r每个网页都会有一个基本的结构标签（也称为骨架标签），页面内容也是在这些基本标签上书写。\nHTML标签：页面中最大的标签，我们称为根标签。 1 \u0026lt;html\u0026gt;\u0026lt;/html\u0026gt; 文档的头部：注意在head标签中我们必须要设置的标签是title。 1 \u0026lt;head\u0026gt;\u0026lt;/head\u0026gt; 文档的标题：让页面拥有一个属于自己的网页标题。 1 \u0026lt;title\u0026gt;\u0026lt;/title\u0026gt; 文档的主体：元素包含文档的所有内容，页面内容基本都是放到body里面的。 1 \u0026lt;body\u0026gt;\u0026lt;/body\u0026gt; \u0026lt;!DOCTYPE\u0026gt;标签：文档类型声明，告诉浏览器用哪种HTML版本来显示网页。\nNotice：\n\u0026lt;!DOCTYPE\u0026gt;声明位于文档中的最前面的位置，处于\u0026lt;html\u0026gt;标签之前。 \u0026lt;!DOCTYPE\u0026gt;不是一个HTML标签。 lang 语言种类：用来定义当前文档显示的语言。\ne.g. English 1 \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt;\u0026lt;/html\u0026gt; e.g. Chinese 1 \u0026lt;html lang=\u0026#34;zh-CN\u0026#34;\u0026gt;\u0026lt;/html\u0026gt; 其实对于文档显示来说，定义成en的文档也可以显示中文，定义成zh-CN的文档也可以显示英文。\n这个属性对浏览器和搜索引擎是有作用的，可以要求翻译。\ncharset 字符集：字符集(Character set)是多个字符的集合，以便计算机能够识别和存储各种文字。\n在\u0026lt;head\u0026gt;标签内，可以通过\u0026lt;meta\u0026gt;标签的charset属性来规定HTML文档应该使用哪种字符编码。\n1 \u0026lt;meta charset=\u0026#34; UTF-8\u0026#34; /\u0026gt; charset常用的值有： GB2312、BIG5、GBK和UTF-8，其中UTF-8也被称为万国码，基本包含了全世界所有国家需要用到的字符。\n语义标签：根据标签的语义，在合适的地方给一个最为合理的标签，可以让页面结构更清晰。\n标题标签：HTML提供了6个等级的网页标题：\u0026lt;h1\u0026gt;,\u0026lt;h2\u0026gt;,\u0026lt;h3\u0026gt;,\u0026lt;h4\u0026gt;,\u0026lt;h5\u0026gt;,\u0026lt;h6\u0026gt;。h是head的缩写，意为头部、标题。\n1 \u0026lt;h1\u0026gt;一级标题\u0026lt;/h1\u0026gt; 作为标题使用，依据重要性递减：一级\u0026gt;二级\u0026gt;\u0026hellip;\n特点：\n加了标题的文字会变的加粗，字号也会依次变大。 一个标题独占一行。 段落标签：在HTML标签中，\u0026lt;p\u0026gt;标签用于定义段落，它可以将整个网页分为若干个段落。p是paragraph的缩写，意为段落。\n1 \u0026lt;p\u0026gt;段落\u0026lt;/p\u0026gt; 特点：\n文本在一个段落中会根据浏览器窗口的大小自动换行。 段落和段落之间保有空隙。 换行标签：在HTML中，一个段落中的文字会从左到右依次排列，直到浏览器窗口的右端，然后才自动换行。如果希望某段文本强制换行显示，就需要使用换行标签\u0026lt;br/\u0026gt;。br是break的缩写，意为打断、换行。\n1 \u0026lt;p\u0026gt;aaaa\u0026lt;br /\u0026gt;aaaaaaa\u0026lt;/p\u0026gt; 特点：\n\u0026lt;br/\u0026gt;是个单标签。 \u0026lt;br/\u0026gt;标签只是简单地开始新的一行，跟段落不一样段落之间会插入一些垂直的间距。 综合案例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1.0\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;水花61分伊戈达拉制胜抢断 西决勇士再胜开拓者总分2-0\u0026lt;/h1\u0026gt; \u0026lt;h4\u0026gt;数据统计：水花兄弟合砍61分\u0026lt;/h4\u0026gt; \u0026lt;p\u0026gt;库里22投11中，三分14投4中，罚球11罚全中得到37分8篮板8助攻，职业生涯季后赛得分30+次数来到35次，超过哈登 排名现役第3位，仅次于詹姆斯和杜兰特。\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;汤普森22投8中，三分8投4中得到24分3篮板2助攻，德拉蒙德格林得到16分10篮板7助攻5盖帽，凯文-鲁尼得到14分7 篮板2助攻，今天勇士有7名替补出场。\u0026lt;/p\u0026gt; \u0026lt;h4\u0026gt;兄弟对决升级：小库里给哥哥造成压力\u0026lt;/h4\u0026gt; \u0026lt;p\u0026gt;库里兄弟是NBA历史上第一对在分区决赛相遇的兄弟。 在西决第1场中，小库里没有给哥哥造成压力，他出场19分钟， 7 投1中只得到3分3篮板2助攻，在场期间输掉10分。\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;但在西决第2场中，小库里攻防两端都打出杰出的表现[全场送出4次抢断，包括直接抢断自己的哥哥库里，在防守端给 库里造成了极大的困扰。\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;作者：\u0026lt;br /\u0026gt;2019-8-8\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 文本格式化标签：粗体、斜体、删除线、下划线。突出重要性，比普通文字重要。\n加粗：\u0026lt;strong\u0026gt;\u0026lt;/strong\u0026gt;或者\u0026lt;b\u0026gt;\u0026lt;/b\u0026gt;。更推荐使用\u0026lt;strong\u0026gt;标签加粗语义更强烈。\n倾斜：\u0026lt;em\u0026gt;\u0026lt;/em\u0026gt;或者\u0026lt;i\u0026gt;\u0026lt;/i\u0026gt;。更推荐使用\u0026lt;em\u0026gt;标签加粗语义更强烈。\n删除线：\u0026lt;del\u0026gt;\u0026lt;/del\u0026gt;或者\u0026lt;s\u0026gt;\u0026lt;/s\u0026gt;。更推荐使用\u0026lt;del\u0026gt;标签加粗语义更强烈。\n下划线：\u0026lt;ins\u0026gt;\u0026lt;/ins\u0026gt;或者\u0026lt;u\u0026gt;\u0026lt;/u\u0026gt;。更推荐使用\u0026lt;ins\u0026gt;标签加粗语义更强烈。\n\u0026lt;div\u0026gt;和\u0026lt;span\u0026gt;标签：无语义，是一个盒子，用来装内容。\n特点： \u0026lt;div\u0026gt;标签用来布局，但是现在一行只能放一个\u0026lt;div\u0026gt;。 大盒子 \u0026lt;span\u0026gt;标签用来布局，一行上可以多个\u0026lt;span\u0026gt;。小盒子 1 2 \u0026lt;div\u0026gt;content\u0026lt;/div\u0026gt; \u0026lt;span\u0026gt;content\u0026lt;/span\u0026gt; 图像标签：在HTML标签中，\u0026lt;img\u0026gt;标签用于定义HTML页面中的图像。\n1 \u0026lt;img src=\u0026#34;图像URL\u0026#34; /\u0026gt; src是图像标签的必须属性，用于指定图像文件的路径和文件名。\n图像属性：\nsrc：图片路径。必须属性。指定图像文件的路径和文件名。 alt：文本。替换文本：图像不能显示的时候显示的文字。 title：文本。提示文本：鼠标放到图像上显示的文字。 width：像素。设置图像的宽度。 height：像素。设置图像的高度。 border：像素。设置图像的边框粗细。 特点：\n图像标签可以拥有多个属性，必须写在标签名的后面。 属性之间不分先后顺序，标签名与属性、属性与属性之间均以空格分开。 属性采取键值对的格式，即key=\u0026quot;value\u0026quot;的格式。 超链接标签：\u0026lt;a\u0026gt;标签用于定义超链接，作用是从一个页面链接到另一个页面。a为anchor的缩写。\n链接的语法格式\n1 \u0026lt;a href=\u0026#34;跳转目标\u0026#34; target=\u0026#34;目标窗口的弹出方式\u0026#34;\u0026gt; 文本或图像 \u0026lt;/a\u0026gt; href(必须属性)：用于指定链接目标的url地址，当为标签应用href属性时，它就具有了超链接的功能。 target：用于指定链接页面的打开方式，其中_self为默认值，_blank为在新窗口中打开方式。 链接的分类\n外部链接 e.g.\n1 \u0026lt;a href=\u0026#34;http://www.baidu.com\u0026#34;\u0026gt; baidu \u0026lt;/a\u0026gt; 内部链接 e.g.\n1 \u0026lt;a href=\u0026#34;index.html\u0026#34;\u0026gt; baidu \u0026lt;/a\u0026gt; 空链接 e.g.\n1 \u0026lt;a href=\u0026#34;#\u0026#34;\u0026gt; baidu \u0026lt;/a\u0026gt; 下载链接：如果href里面地址是一个文件或者压缩包(.exe or .zip)，会下载这个文件。 e.g.\n1 \u0026lt;a href=\u0026#34;xxx.zip\u0026#34;\u0026gt; baidu \u0026lt;/a\u0026gt; 网页元素链接：在网页中的各种网页元素，如文本、图像、表格、音频、视频等都可以添加超链接。 e.g.\n1 \u0026lt;a href=\u0026#34;http://www.baidu.com\u0026#34;\u0026gt; \u0026lt;img src=\u0026#34;img.jpg\u0026#34;\u0026gt; \u0026lt;/a\u0026gt; 锚点链接：点击后快速定位到页面中的某个位置\n在链接文本的href属性中，设置属性值为#name的形式，e.g. 1 \u0026lt;a href= \u0026#34;#two\u0026#34;\u0026gt;第2集\u0026lt;/a\u0026gt; 找到目标位置标签，里面添加一个id属性=刚才的name，e.g.```html 第2集介绍 ``` 注释和特殊字符\n注释：注释以\u0026lt;!--开头，以--\u0026gt;结束。\n快捷键：Ctrl + / 特殊字符\n表格标签\n基本语法\n1 2 3 4 5 6 7 \u0026lt;table\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt; \u0026lt;/td\u0026gt; ... \u0026lt;/tr\u0026gt; ... \u0026lt;/table\u0026gt; \u0026lt;table\u0026gt; \u0026lt;/table\u0026gt;是用于定义表格的标签。 \u0026lt;tr\u0026gt; \u0026lt;/tr\u0026gt;标签用于定义表格中的行，必须嵌套在\u0026lt;table\u0026gt; \u0026lt;/table\u0026gt;标签中。 \u0026lt;td\u0026gt; \u0026lt;/td\u0026gt;用于定义表格中的单元格，必须嵌套在\u0026lt;tr\u0026gt; \u0026lt;/tr\u0026gt;标签中。td为table data缩写，指单元格内容。 表头单元格标签：一般表头单元格位于表格的第一行或第一列，表头单元格里面的文本内容加粗居中显示。th为table head缩写。\n1 2 3 4 5 6 7 \u0026lt;table\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;th\u0026gt; \u0026lt;/th\u0026gt; ... \u0026lt;/tr\u0026gt; ... \u0026lt;/table\u0026gt; 表格相关属性：一般通过css来设置。\nalign：left、center、right。规定表格相对周围元素的对齐方式。 border：1或\u0026quot;\u0026quot;。规定表格单元是否拥有边框，默认为\u0026quot;\u0026quot;，表示没有边框 cellpadding：像素值。规定单元边沿与其内容之间的空白，默认1像素。 cellspacing：像素值。规定单元格之间的空白，默认2像素。 width：像素值或百分比。规定表格的宽度。 表格结构标签：在表格标签中分别用： \u0026lt;thead\u0026gt;标签表格的头部区域、\u0026lt;tbody\u0026gt;标签表格的主体区域这样可以更好的分清表格结构。\n\u0026lt;thead\u0026gt; \u0026lt;/thead\u0026gt;：用于定义表格的头部。\u0026lt;thead\u0026gt; 内部必须拥有\u0026lt;tr\u0026gt;标签。一般是位于第一行。 \u0026lt;tbody\u0026gt; \u0026lt;/tbody\u0026gt;：用于定义表格的主体，主要用于放数据本体。 \u0026lt;thead\u0026gt; \u0026lt;/thead\u0026gt;和\u0026lt;tbody\u0026gt; \u0026lt;/tbody\u0026gt;都放在\u0026lt;table\u0026gt; \u0026lt;/table\u0026gt;内。 合并单元格\n合并单元格方式： 跨行合并：rowspan=\u0026quot;合并单元格个数\u0026quot;。最上侧单元格为目标单元格，在此单元格中写合并代码。 跨列合并：colspan=\u0026quot;合并单元格个数\u0026quot;。最左侧单元格为目标单元格，在此单元格中写合并代码。 操作步骤： 确定跨行还是跨列 找到目标单元格，加入属性合并方式=\u0026quot;合并单元格个数\u0026quot; 删除多余的单元格。 列表标签：用来布局，整齐整洁有序，可分三类：无序列表、有序列表、自定义列表。\n无序列表：\u0026lt;ul\u0026gt;标签表示HTML页面中项目的无序列表，一般会以项目符号呈现列表项，而列表项使用\u0026lt;li\u0026gt;标签定义。无序列表的基本语法格式如下：\n1 2 3 4 5 \u0026lt;ul\u0026gt; \u0026lt;li\u0026gt;列表项1\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;列表项2\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;列表项3\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; 无序列表的各个列表项之间没有顺序级别之分，并列的。 \u0026lt;ul\u0026gt;\u0026lt;/ul\u0026gt;只能嵌套\u0026lt;li\u0026gt;\u0026lt;/li\u0026gt;，直接在\u0026lt;ul\u0026gt;\u0026lt;/ul\u0026gt;标签中输入其他标签或者文字的做法也是不被允许的。 \u0026lt;li\u0026gt;\u0026lt;/li\u0026gt;相当于一个容器，里面可以容纳所有元素，放所有的标签。 无序列表会带有自己的样式属性，但在实际使用时，我们会使用css来设置。 有序列表：\u0026lt;ol\u0026gt;标签表示HTML页面中项目的有序列表，列表排序以数字来显示，并且使用\u0026lt;li\u0026gt;标签定义列表项。有序列表的基本语法格式如下：\n1 2 3 4 5 \u0026lt;ol\u0026gt; \u0026lt;li\u0026gt;列表项1\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;列表项2\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;列表项3\u0026lt;/li\u0026gt; \u0026lt;/ol\u0026gt; \u0026lt;ol\u0026gt;\u0026lt;/ol\u0026gt;中只能嵌套\u0026lt;li\u0026gt;\u0026lt;/li\u0026gt;，直接在\u0026lt;ol\u0026gt;\u0026lt;/ol\u0026gt;标签中输入其他标签或者文字的做法是不被允许的。 \u0026lt;li\u0026gt;\u0026lt;/li\u0026gt;相当于一个容器，可以容纳所有元素，放所有的标签。 有序列表会带有自己的样式属性，但在实际使用时，我们会使用css来设置。` 自定义列表：自定义列表常用于对术语或名词进行解释和描述，定义列表的列表项前没有任何项目符号。在HTML标签中，\u0026lt;dl\u0026gt;标签用于定义描述列表(或定义列表)，该标签会与\u0026lt;dt\u0026gt; (定义项目/名字)和\u0026lt;dd\u0026gt;(描述每一个项目/名字)一起使用。其基本语法如下：\n1 2 3 4 5 \u0026lt;dl\u0026gt; \u0026lt;dt\u0026gt;名词1\u0026lt;/dt\u0026gt; \u0026lt;dd\u0026gt;名词1解释1\u0026lt;/dd\u0026gt; \u0026lt;dd\u0026gt;名词1解释2\u0026lt;/dd\u0026gt; \u0026lt;/dl\u0026gt; \u0026lt;dl\u0026gt;\u0026lt;/dl\u0026gt;中只能嵌套\u0026lt;dt\u0026gt;\u0026lt;/dt\u0026gt;和\u0026lt;dd\u0026gt;\u0026lt;/dd\u0026gt; \u0026lt;dt\u0026gt;\u0026lt;/dt\u0026gt;和\u0026lt;dd\u0026gt;\u0026lt;/dd\u0026gt;个数没有限制，通常一个\u0026lt;dt\u0026gt;对应多个\u0026lt;dd\u0026gt;。 \u0026lt;dt\u0026gt;和\u0026lt;dd\u0026gt;里可以容纳所有元素，放所有的标签。 表单标签：用于和用户交互，收集用户信息、用户资料。一个完整的表单由表单域、表单控件和提示信息组成。\n表单域；包含表单元素的区域。\u0026lt;form\u0026gt;标签用于定义表单域\u0026lt;form\u0026gt;会把它范围内的表单元素信息提交给服务器。\n1 2 3 \u0026lt;form action=\u0026#34;url地址\u0026#34; method=\u0026#34;提交方式\u0026#34; name=\u0026#34;表单域名称\u0026#34;\u0026gt; 各种表单元素控件 \u0026lt;/form\u0026gt; 属性 action：用于指定接收并处理表单数据的服务器程序的url地址。 method：用于设置表单数据的提交方式，其取值为get或post。 name：用于指定表单的名称，以区分同一个页面中的多个表单域。 表单元素：允许用户在表单中输入或者选择的内容控件。\ninput输入表单元素：\u0026lt;input\u0026gt;标签用于收集用户信息。在\u0026lt;input\u0026gt;标签中，包含一个type属性，根据不同的type属性值，输入字段拥有很多种形式(可以是文本字段、复选框、掩码后的文本控件、单选按钮、按钮等)。\u0026lt;input /\u0026gt;是单标签。\n1 \u0026lt;input type=\u0026#34;属性值\u0026#34; /\u0026gt; type属性值：\nbutton：定义可点击按钮(多数情况下，用于通过JavaScript启动脚本)，不提交表单域中的数据。 checkbox：定义复选框。 file：定义输入字段和“浏览”按钮，供文件上传。 hidden：定义隐藏的输入字段。 image：定义图像形式的提交按钮。 password：定义密码字段。该字段中的字符被掩码。 radio：定义单选按钮。 reset：定义重置按钮。重置按钮会清除表单中的所有数据，回到默认状态。 submit：定义提交按钮。提交按钮会把表单域中所有表单数据发送到服务器。 text：定义单行的输入字段，用户可在其中输入文本。默认宽度为20个字符。 name属性：定义input元素的名称。name和value是每个表单元素都有的属性值，主要给后台人员使用。name是表单元素的名字，要求单选按钮和复选框要有相同的name值（radio（或者checkbox）如果是一组，我们必须给他们命名相同的名字）。\nvalue属性：规定input元素的值。name和value是每个表单元素都有的属性值，主要给后台人员使用。可以默认显示信息。\nchecked属性：checked=\u0026quot;checked\u0026quot;，规定此input元素首次加载时应当被选中。checked属性主要针对单选按钮和复选框，主要作用是一打开界面，就默认选择其中某个表单元素。\nmaxlength属性：规定输入字段中的字符的最大长度。maxlength是用户可以输入的最多的字符数。\n\u0026lt;label\u0026gt;标签：为input元素定义标注(标签)。\u0026lt;label\u0026gt;标签用于绑定一个表单元素当点击\u0026lt;label\u0026gt;标签内的文本时，浏览器就会自动将焦点（光标）转到或者选择对应的表单元素上，用来增加用户体验。核心：\u0026lt;label\u0026gt;中的for属性的值和\u0026lt;input\u0026gt;中的id属性的值相同 1 2 \u0026lt;label for=\u0026#34;sex\u0026#34;\u0026gt;male\u0026lt;/label\u0026gt; \u0026lt;input type=\u0026#34;radio\u0026#34; name=\u0026#34;sex\u0026#34; id=\u0026#34;sex\u0026#34; /\u0026gt; select下拉表单元素：\u0026lt;select\u0026gt;标签定义下拉列表。\n1 2 3 4 5 \u0026lt;select\u0026gt; \u0026lt;option\u0026gt; 选项1 \u0026lt;/option\u0026gt; \u0026lt;option\u0026gt; 选项2 \u0026lt;/option\u0026gt; \u0026lt;option\u0026gt; 选项3 \u0026lt;/option\u0026gt; \u0026lt;/select\u0026gt; \u0026lt;select\u0026gt;中至少包含一对\u0026lt;option\u0026gt;。 在\u0026lt;option\u0026gt;中定义selected=\u0026quot;selected\u0026quot;时，当前项即为默认选中项。 textarea文本域元素：当用户输入内容较多的情况下，我们就不能使用文本框表单了，此时我们可以使用\u0026lt;textarea\u0026gt;标签。\u0026lt;textarea\u0026gt;标签用于定义多行文本输入的控件。\n1 \u0026lt;textarea rows=\u0026#34;3\u0026#34; col=\u0026#34;20\u0026#34;\u0026gt;默认文本内容\u0026lt;/textarea\u0026gt; 其中两个属性rows=\u0026quot;显示的行数\u0026quot;和col=\u0026quot;每行中的字符数\u0026quot;，在实际开发中不会使用，用css来调整大小。 HTML查阅文档：w3c ","date":"2025-02-18T22:42:40+08:00","image":"https://example.com/html-logo.png","permalink":"https://example.com/p/notes-on-html/","title":"Notes on HTML"},{"content":"Update Hugo To Hugo-extended\rWhy not Hugo but Hugo-extended?\nSome themes use SCSS and TypeScript, that\u0026rsquo;s why Hugo extended version is required. If you are using a non-extended Hugo installation, you will get the following error:\n1 Error: Error building site: TOCSS: failed to transform \u0026#34;scss/style.scss\u0026#34; (text/x-scss): this feature is not available in your current Hugo version Download\rGet to https://github.com/gohugoio/hugo/releases and download e.g. hugo_extended_0.143.1_windows-amd64.zip. Or just winget in the cmd:\n1 winget install Hugo.Hugo.Extended Extract\rExtract the zip in the suitable location:\n1 2 3 4 5 PS D:\\\u0026gt; tree .\\hugo_extended /f /a D:\\HUGO_EXTENDED hugo.exe LICENSE README.md Verify\rVerify the installation:\n1 2 PS D:\\\u0026gt; D:/hugo_extended/hugo version hugo v0.143.1-0270364a347b2ece97e0321782b21904db515ecc+extended windows/amd64 BuildDate=2025-02-04T08:57:38Z VendorInfo=gohugoio After that, the origin hugo D:/hugo_dir can be deprecated and all the commands e.g. D:/hugo_dir/hugo can be changed to D:/hugo_extended/hugo. ✅\n","date":"2025-02-17T18:57:48+08:00","image":"https://example.com/hugo-logo-wide.png","permalink":"https://example.com/p/update-hugo-to-hugo-extended/","title":"Update Hugo To Hugo-extended"},{"content":"Solve the problem of export latex code in Markdown as pdf\rFirst, download VSCode and the Markdown All in One extension.\nSecond, Ctrl + Shift + P and input Print current document to HTML.\nA html file is already created and with well-displayed latex equation.\n","date":"2024-12-09T18:50:29+08:00","permalink":"https://example.com/p/some-skills-on-exporting-latex-in-markdown-as-pdf/","title":"Some Skills on Exporting Latex in Markdown as pdf"},{"content":"Python permanently modifies pip mirror source\rIf change the mirror source to Tsinghua Mirror Source, type the following code in the Terminal:\n1 pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple Install Cuda In Virtual Environment of Conda\rFirst Run the code in the Terminal to determine the version of Cuda:\n1 nvidia-smi CUDA Version is the version of cuda that the computer can support, so the version of cuda we want to install needs to be \u0026lt;= CUDA Version (backward compatible)\nRun the code in order in the Terminal:\n1 2 3 4 5 6 7 8 9 conda create -n env_name python=3.10 conda activate env_name # conda search cudatoolkit --info conda install cudatoolkit=11.8.0 conda install cudnn # pytorch official website: https://pytorch.org/get-started/locally/ conda install pytorch torchvision torchaudio pytorch-cuda=12.4 -c pytorch -c nvidia After installing the Cuda, Run the code in order in the Terminal and verify that Cuda was installed successfully:\n1 2 3 4 conda activate env_name python import torch print(torch.cuda.is_available()) ","date":"2024-10-18T15:28:15+08:00","permalink":"https://example.com/p/some-skills-on-modifying-pip-mirror-source-and-installing-cuda-in-conda/","title":"Some Skills on Modifying Pip Mirror Source and Installing Cuda in Conda"},{"content":"Image Pre-processing/Transformation\r1 2 3 4 5 6 7 8 9 10 11 train_tfm = transforms.Compose([ # Resize the images into the fixed size transforms.Resize((128, 128)), \u0026#39;\u0026#39;\u0026#39; Do some Image Enhancement \u0026#39;\u0026#39;\u0026#39; # ToTensor() should be the last transformation transforms.ToTensor(), ]) Geometric Transformations\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Rotation transform_rotate = transforms.RandomRotation(degrees=30) # Translation transform_translate = transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)) # Flipping transform_flip = transforms.RandomHorizontalFlip(p=0.5) # Scaling transform_scale = transforms.RandomResizedCrop(size=224, scale=(0.8, 1.0)) # Shearing transform_shear = transforms.RandomAffine(degrees=0, shear=20) Color Transformations\r1 2 3 4 5 6 7 8 9 10 11 # Brightness Adjustment transform_brightness = transforms.ColorJitter(brightness=0.5) # Contrast Adjustment transform_contrast = transforms.ColorJitter(contrast=0.5) # Satuation Adjustment transform_saturation = transforms.ColorJitter(saturation=0.5) # Hue Adjustment transform_hue = transforms.ColorJitter(hue=0.2) Cropping and Padding\r1 2 3 4 5 # Random Cropping transform_random_crop = transforms.RandomCrop(size=224) # Padding transform_padding = transforms.Pad(padding=4) Image Enhancement\r1 2 # Random Erasing transform_random_erasing = transforms.RandomErasing(p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3), value=0) ","date":"2024-08-28T14:14:07+08:00","permalink":"https://example.com/p/some-skills-on-image-processing/","title":"Some Skills on Image Processing"},{"content":"Learning Diffusers\rInstallation\rWith pip\n1 pip install --upgrade diffusers[torch] With conda\n1 conda install -c conda-forge diffusers Use\rDirectly call the pretrained model uploaded in diffusers:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 import torch from diffusers import DDPMPipeline device = torch.device(\u0026#34;cuda\u0026#34; if torch.cuda.is_available() else \u0026#34;cpu\u0026#34;) # Load the butterfly pipeline butterfly_pipeline = DDPMPipeline.from_pretrained( \u0026#34;johnowhitaker/ddpm-butterflies-32px\u0026#34; ).to(device) # Create 8 images images = butterfly_pipeline(batch_size=8).images # View the result make_grid(images) Example\rStep 0: Login and Initialize some useful functions\r1 2 3 4 # Login from huggingface_hub import notebook_login notebook_login() # copy the token in 1 2 3 4 5 6 7 8 9 10 11 12 13 import numpy as np import torch import torch.nn.functional as F from matplotlib import pyplot as plt from PIL import Image def show_images(x): \u0026#34;\u0026#34;\u0026#34;Given a batch of images x, make a grid and convert to PIL\u0026#34;\u0026#34;\u0026#34; x = x * 0.5 + 0.5 # Map from (-1, 1) back to (0, 1) grid = torchvision.utils.make_grid(x) grid_im = grid.detach().cpu().permute(1, 2, 0).clip(0, 1) * 255 grid_im = Image.fromarray(np.array(grid_im).astype(np.uint8)) return grid_im Step 1: Download a training dataset\rFor this example, we\u0026rsquo;ll use a dataset of images from the Hugging Face Hub. Specifically, this collection of 1000 butterfly pictures.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 import torchvision from datasets import load_dataset from torchvision import transforms # Load dataset from https://huggingface.co/datasets/huggan/smithsonian_butterflies_subset dataset = load_dataset(\u0026#34;huggan/smithsonian_butterflies_subset\u0026#34;, split=\u0026#34;train\u0026#34;) \u0026#39;\u0026#39;\u0026#39; # Or load images from a local folder dataset = load_dataset(\u0026#34;imagefolder\u0026#34;, data_dir=\u0026#34;path/to/folder\u0026#34;) \u0026#39;\u0026#39;\u0026#39; # We\u0026#39;ll train on 32-pixel square images, but you can try larger sizes too image_size = 32 # You can lower your batch size if you\u0026#39;re running out of GPU memory batch_size = 64 # Define data augmentations preprocess = transforms.Compose( [ transforms.Resize((image_size, image_size)), # Resize transforms.RandomHorizontalFlip(), # Randomly flip (data augmentation) transforms.ToTensor(), # Convert to tensor (0, 1) transforms.Normalize([0.5], [0.5]), # Map to (-1, 1) ] ) def transform(examples): images = [preprocess(image.convert(\u0026#34;RGB\u0026#34;)) for image in examples[\u0026#34;image\u0026#34;]] return {\u0026#34;images\u0026#34;: images} dataset.set_transform(transform) # Create a dataloader from the dataset to serve up the transformed images in batches; Save the images in the dataloader train_dataloader = torch.utils.data.DataLoader( dataset, batch_size=batch_size, shuffle=True ) View the first 8 image examples in the dataset:\n1 2 3 xb = next(iter(train_dataloader))[\u0026#34;images\u0026#34;].to(device)[:8] print(\u0026#34;X shape:\u0026#34;, xb.shape) show_images(xb).resize((8 * 64, 64), resample=Image.NEAREST) Step 2: Define the Scheduler\rOur plan for training is to take these input images and add noise to them, then feed the noisy images to the model. And during inference, we will use the model predictions to iteratively remove noise. In diffusers, these processes are both handled by the scheduler.\nThe noise schedule determines how much noise is added at different timesteps.\n1 2 3 from diffusers import DDPMScheduler # Define a Scheduler noise_scheduler = DDPMScheduler(num_train_timesteps=1000) 1 2 3 4 5 6 7 # Add noise and View the process of noise-adding # The core is add_noise() timesteps = torch.linspace(0, 999, 8).long().to(device) noise = torch.randn_like(xb) # Random a noise from standard Guassian N(0,I) noisy_xb = noise_scheduler.add_noise(xb, noise, timesteps) print(\u0026#34;Noisy X shape\u0026#34;, noisy_xb.shape) show_images(noisy_xb).resize((8 * 64, 64), resample=Image.NEAREST) Step 3: Define the Model\rMost diffusion models use architectures that are some variant of a U-Net and that\u0026rsquo;s what we\u0026rsquo;ll use here.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 from diffusers import UNet2DModel # Create a model model = UNet2DModel( sample_size=image_size, # the target image resolution in_channels=3, # the number of input channels, 3 for RGB images out_channels=3, # the number of output channels layers_per_block=2, # how many ResNet layers to use per UNet block block_out_channels=(64, 128, 128, 256), # More channels -\u0026gt; more parameters down_block_types=( \u0026#34;DownBlock2D\u0026#34;, # a regular ResNet downsampling block \u0026#34;DownBlock2D\u0026#34;, \u0026#34;AttnDownBlock2D\u0026#34;, # a ResNet downsampling block with spatial self-attention \u0026#34;AttnDownBlock2D\u0026#34;, ), up_block_types=( \u0026#34;AttnUpBlock2D\u0026#34;, \u0026#34;AttnUpBlock2D\u0026#34;, # a ResNet upsampling block with spatial self-attention \u0026#34;UpBlock2D\u0026#34;, \u0026#34;UpBlock2D\u0026#34;, # a regular ResNet upsampling block ), ) model.to(device) When dealing with higher-resolution inputs you may want to use more down and up-blocks, and keep the attention layers only at the lowest resolution (bottom) layers to reduce memory usage.\n1 2 3 4 # Check that passing in a batch of data and some random timesteps produces an output the same shape as the input data: with torch.no_grad(): model_prediction = model(noisy_xb, timesteps).sample model_prediction.shape Step 4: Training: Create a Training Loop\rFor each batch of data, we\nSample some random timesteps Noise the data accordingly Feed the noisy data through the model Compare the model predictions with the target (i.e. the noise in this case) using mean squared error as our loss function Update the model parameters via loss.backward() and optimizer.step() 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 # Set the noise scheduler noise_scheduler = DDPMScheduler( num_train_timesteps=1000, beta_schedule=\u0026#34;squaredcos_cap_v2\u0026#34; ) # Training loop optimizer = torch.optim.AdamW(model.parameters(), lr=4e-4) losses = [] # Loop through the training epoch for epoch in range(30): # Loop through all data for step, batch in enumerate(train_dataloader): # Set the Scheduler # Load the data clean_images = batch[\u0026#34;images\u0026#34;].to(device) # Sample noise to add to the images noise = torch.randn(clean_images.shape).to(clean_images.device) bs = clean_images.shape[0] # Sample a random timestep for each image timesteps = torch.randint( 0, noise_scheduler.num_train_timesteps, (bs,), device=clean_images.device ).long() # Add noise to the clean images according to the noise magnitude at each timestep noisy_images = noise_scheduler.add_noise(clean_images, noise, timesteps) # Input the noisy_images to the model and Get the model prediction noise_pred = model(noisy_images, timesteps, return_dict=False)[0] # Calculate the loss loss = F.mse_loss(noise_pred, noise) loss.backward(loss) losses.append(loss.item()) # Update the model parameters with the optimizer optimizer.step() optimizer.zero_grad() if (epoch + 1) % 5 == 0: loss_last_epoch = sum(losses[-len(train_dataloader) :]) / len(train_dataloader) print(f\u0026#34;Epoch:{epoch+1}, loss: {loss_last_epoch}\u0026#34;) 1 2 3 4 5 # Plot the loss fig, axs = plt.subplots(1, 2, figsize=(12, 4)) axs[0].plot(losses) axs[1].plot(np.log(losses)) plt.show() Step 5: Generate Images\rMethod 1: Create a pipeline 1 2 3 4 from diffusers import DDPMPipeline image_pipe = DDPMPipeline(unet=model, scheduler=noise_scheduler) pipeline_output = image_pipe() pipeline_output.images[0] 1 2 # save a pipeline to a local folder like so: image_pipe.save_pretrained(\u0026#34;my_pipeline\u0026#34;) 1 2 3 4 # Inspecting the folder contents: ls my_pipeline/ # Output: model_index.json scheduler unet # The `scheduler` and `unet` subfolders contain everything needed to re-create those components. For example, inside the `unet` folder you\u0026#39;ll find the model weights (`diffusion_pytorch_model.bin`) alongside a config file which specifies the UNet architecture. Method 2: Writing a Sampling Loop 1 2 3 4 5 6 7 8 9 10 11 12 13 # Random starting point (8 random images): sample = torch.randn(8, 3, 32, 32).to(device) # A specific process of denoising and generating the images for i, t in enumerate(noise_scheduler.timesteps): # Get model pred with torch.no_grad(): residual = model(sample, t).sample # Update sample with step sample = noise_scheduler.step(residual, t, sample).prev_sample show_images(sample) ","date":"2024-08-11T12:09:12+08:00","permalink":"https://example.com/p/diffusers/","title":"Diffusers"},{"content":"\r","date":"2024-08-02T11:22:51+08:00","permalink":"https://example.com/p/2024.08.02/","title":"2024.08.02"},{"content":"Difference Between PCA and AutoEncoder\rPCA\rSuppose there are m n-dimensional data, $ X_{n \\times m} = [x_1, x_2,\u0026hellip;, x_m]$, where each $x$ is an n-dimensional column vector.\nReduce Dimensionality\rDecentralize the data: $x_{i} = x_{i} - \\frac{1}{m} \\sum_{j=1}^{m} x_{j}$ and update $X$ Calculate the Covariance matrix: $C = \\frac{1}{m} XX^T$ Take eigenvalue decomposition of the Covariance matrix $C$ and get the eigenvector matrix (the eigenvector is arranged in columns from the related largest to smallest eigenvalues). Take the first $k$ columns to form the matrix $P_{n \\times k}$ Project the original data into the $P$ coordinate system to get the dimensionality reduced data: $Y_{k \\times m} = P_{n \\times k}^T \\times X_{n \\times m}$, which is a linear transformation. The dimension of the data after PCA is changed compared to the origin data. Data Reconstruction\rPCA is lossy, that is, the compressed data does not maintain all the information of the original data, so the compressed data can not be restored back to the original high-dimensional data, but the restored data can be regarded as an approximation of the original data: $X_{n \\times m}^{\u0026rsquo;} = P_{n \\times k} Y_{k \\times m}$\nAutoEncoder\rEncoder\rThe original data $X$ is input, and then compressed according to the network model, the original high dimensional data $X$ is compressed into low dimensional data C, and these low dimensional data is usually customarily referred to as latent vector, the original data after the activation function operation of the nonlinear hidden layer, the original data will be transformed into a low dimensional space, this space is considered to be the high-feature space. After the original data is operated by the activation function of the nonlinear hidden layer, the original data will be transformed to a low-dimensional space, which is considered as the high-feature space. AutoEncoder is a non-linear transformation. The dimension of the data after Encoder is the same as the origin data.\nDecoder\rConvert the original implicit layer data back into the original data space.\nHow to design the network\rFor simple datasets such as MNIST, a network with 1-2 hidden layers is usually sufficient. However, a network with 3 or more hidden layers can capture more complex features, but can also lead to overfitting.\nAs for MNIST, the number of nodes in the hidden layer should decrease layer by layer, usually the number of nodes in the last layer of the encoder, i.e., the dimension of the potential space, can be chosen from 32 to 128.\nCode Example:\rAutoEncoder on MNIST dataset:\n1 2 3 4 5 6 7 8 self.encoder = nn.Sequential( nn.Linear(28 * 28, 128), nn.ReLU(True), nn.Linear(128, 64), nn.ReLU(True), nn.Linear(64, 32) ) # Design of the network can be changed 1 2 3 4 5 6 7 8 9 self.decoder = nn.Sequential( nn.Linear(32, 64), nn.ReLU(True), nn.Linear(64, 128), nn.ReLU(True), nn.Linear(128, 28 * 28), nn.Tanh() ) # Design of the network can be changed ","date":"2024-07-20T14:13:42+08:00","permalink":"https://example.com/p/pca-and-autoencoder/","title":"PCA and AutoEncoder"},{"content":"Study on Score-Based Generative Modeling\r(●\u0026rsquo;◡\u0026rsquo;●)\nAbout Score-Based Generative Modeling: the following article has given a clear explanation: Diffusion Model: SDE\nA simple conclusion of the Score-Based Generative Modeling through Stochastic Differential Equations: Generalization of discrete models such as DDPM to continuous SDE forms, through predictor-corrector samplers to correct the solution of a numerical SDE solver.\n","date":"2024-07-18T23:45:09+08:00","permalink":"https://example.com/p/2024.07.18/","title":"2024.07.18"},{"content":"Build A Github Repository\rԅ(¯﹃¯ԅ)\nInitialize\rCreate a Github repository and set the repository name.\nLink to Github\rRun the code in order in the PowerShell under the target directory:\n1 2 3 4 5 6 cd dir_name git init git add . git commit -m \u0026#34;first commit\u0026#34; git remote add origin https://github.com/.... git push origin main Hugo: Local Preview\rHugo comes with a built-in development server that allows you to preview the site in real time on the server:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 cd D:/html D:/hugo_extended/hugo server Watching for changes in D:\\html\\{archetypes,assets,content,data,i18n,layouts,static,themes} Watching for config changes in D:\\html\\hugo.yaml, D:\\html\\themes\\hugo-theme-stack\\config.yaml Start building sites … hugo v0.143.1-0270364a347b2ece97e0321782b21904db515ecc+extended windows/amd64 BuildDate=2025-02-04T08:57:38Z VendorInfo=gohugoio | EN -------------------+----- Pages | 48 Paginator pages | 2 Non-page files | 0 Static files | 13 Processed images | 0 Aliases | 16 Cleaned | 0 Built in 409 ms Environment: \u0026#34;development\u0026#34; Serving pages from disk Running in Fast Render Mode. For full rebuilds on change: hugo server --disableFastRender Web Server is available at http://localhost:1313/ (bind address 127.0.0.1) Press Ctrl+C to stop It supports for real-time revising and updating.\nHugo: Write A Post\rNew a post\r( •̀ .̫ •́ )✧\nRun the code in order in the PowerShell:\n1 2 cd D:/html D:/hugo_extended/hugo new post/fileName.md Push to Github\r(｡･ω･｡)ﾉ♡\nRun the code in order in the PowerShell:\n1 2 3 4 5 D:/hugo_extended/hugo cd public git add . git commit -m \u0026#34;test\u0026#34; git push origin main ","date":"2024-07-16T14:16:38+08:00","permalink":"https://example.com/p/starting-from-scratch-creating-and-pushing-your-blog-posts-with-hugo-and-git/","title":"Starting from Scratch: Creating and Pushing Your Blog Posts with Hugo and Git"},{"content":"Hello Serendpity\u0026rsquo;s Blog\rThis is Serendpity\u0026rsquo;s first blog post. Love you all! ( •̀ ω •́ )y\n","date":"2024-07-16T13:40:30+08:00","permalink":"https://example.com/p/my-first-blog/","title":"My First Blog"}]